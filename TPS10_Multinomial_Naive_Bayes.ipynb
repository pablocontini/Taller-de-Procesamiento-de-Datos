{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMuisn3tiSUMibQcH+PsgtR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pablocontini/Taller-de-Procesamiento-de-Datos/blob/main/TPS10_Multinomial_Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Enunciado"
      ],
      "metadata": {
        "id": "GlkGNFUDgwT_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Multinomial Naive Bayes**\n",
        "\n",
        "La base de datos *BuzzFeed-Webis Fake News Corpus 2016* posee diferentes artículos periodísticos de una semana cercana a las elecciones estadounidenses de ese año. Se desea entrenar un algoritmo Multinomial Naive Bayes capaz de clasificar los artículos en \"*mayormente falso*\", \"*mayormente verdadero*\", \"*mezcla de verdadero y falso*\" y \"*sin contenido factual*\".\n",
        "\n",
        "(a) *Exploración de datos*:\n",
        "- Descargar la base de datos en $\\texttt{https://zenodo.org/record/1239675/files/articles.\n",
        "zip?download=1}$.\n",
        "- Construir la base de datos. <img src=\"https://i.ibb.co/tTfkc8DH/image.png\" width=\"25\" />: Puede usar el siguiente código:\n",
        "```python\n",
        "import xml.etree.ElementTree as ET\n",
        "data = {\"mainText\": [], \"orientation\": [], \"veracity\": []}\n",
        "for filename in os.listdir(\"articles/\"):\n",
        "    root = ET.parse(f\"articles/{filename}\").getroot()\n",
        "    for elem in root:\n",
        "        if elem.tag in data.keys():\n",
        "            data[elem.tag].append(elem.text)\n",
        "data = pd.DataFrame(data)\n",
        "data = data[data.notna().all(axis=\"columns\")]\n",
        "```\n",
        "- Utilice el comando $\\texttt{train_test_split}$ (sklearn) para definir dos conjuntos de datos. El\n",
        "conjunto de entrenamiento debe contener el 80\\% de las muestras, el resto serán de testeo.\n",
        "- Utilizando $\\texttt{CountVectorizer}$ (sklearn) pre-procesar los datos del texto principal de los artículos. <img src=\"https://i.ibb.co/tTfkc8DH/image.png\" width=\"25\" />: Se recomienda convertir el texto a minúscula, utilizar como *Stop Words* las palabras estándar del idioma inglés, eliminar palabras que aparecen en más del 60\\% de los documentos y descartar las palabras vistas en menos de 3 documentos.\n",
        "\n",
        "(b) *Entrenamiento*: Implementar un MNB de $\\alpha=(1,1,\\dots,1)$ que prediga la veracidad de un artículo a partir de su texto principal (pre-procesado). El código debe estar estructurado de la siguiente manera:\n",
        "\n",
        "```python\n",
        "class MNB:\n",
        "    # Inicializar atributos y declarar hiperparámetros\n",
        "    def __init__(self,...\n",
        "    # Etapa de entrenamiento\n",
        "    def fit(self,X,y):\n",
        "    # Etapa de testeo soft\n",
        "    def predict_proba(self,X):\n",
        "    # Etapa de testeo hard (no repetir código)\n",
        "    def predict(self,X):\n",
        "```\n",
        "\n",
        "(c) *Inferencia*: **Implementar** un método a la clase anterior que calcule el *accuracy* y la *Macro-F1*.\n",
        "\n",
        "Evaluar dichas métricas en el conjunto de testeo. ¿Por qué dan tan diferentes? <img src=\"https://i.ibb.co/tTfkc8DH/image.png\" width=\"25\" />: Para el cálculo de la F1 debe considerar el caso de *precisión* y *recall* nulas.\n",
        "\n",
        "(d) *Orientación*: Repetir el ejercicio, pero para clasificar la orientación política del portal donde fue publicada la noticia (izquierda, derecha o mainstream) a partir del texto principal preprocesado. ¿Siguen siendo válidas las conclusiones extraídas anteriormente? Justificar."
      ],
      "metadata": {
        "id": "mRmo5t9Jgyqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (a) Exploración de datos"
      ],
      "metadata": {
        "id": "yPve9_XfnGRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset contiene la producción de 9 editoriales en una semana cercana a las elecciones estadounidenses. Entre las editoriales seleccionadas se encuentran 6 con un fuerte componente partidista (tres de izquierda y tres de derecha), y tres de medios tradicionales. Durante siete días laborables (del 19 al 23 de septiembre y del 26 al 27 de septiembre), periodistas profesionales de BuzzFeed verificaron cada publicación y artículo de noticias enlazado de las 9 editoriales. En total, se revisaron 1627 artículos: 826 de medios tradicionales, 256 de izquierda y 545 de derecha. El desequilibrio entre categorías se debe a las diferentes frecuencias de publicación.\n",
        "\n",
        "Según el archivo `overview.csv`, este dataset tiene múltiples atributos adicionales al cuerpo completo del artículo:\n",
        "- Metadatos del artículo:\n",
        "  - `author`: autor del artículo (si está disponible).\n",
        "  - `published`: fecha de publicación.\n",
        "  - `title`: título del artículo.\n",
        "  - `url`: enlace original de la noticia.\n",
        "  - `id`: identificador único de cada artículo.\n",
        "  - `publisher`: nombre del portal o medio donde fue publicado.\n",
        "- `orientation`: orientación política del medio:\n",
        "  - `left` (izquierda)\n",
        "  - `right` (derecha)\n",
        "  - `mainstream` (medios tradicionales)\n",
        "- `veracity`: etiqueta de veracidad asignada por BuzzFeed:\n",
        "  - `mostly true` (mayormente cierto)\n",
        "  - `mostly false` (mayormente falso)\n",
        "  - `mixture of true and false` (mezcla de verdadero y falso)\n",
        "  - `no factual content` (sin contenido fáctico)"
      ],
      "metadata": {
        "id": "tO-syOx8BecC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Descarga y descompresión del dataset"
      ],
      "metadata": {
        "id": "W7E8sdtHnmtY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En primer lugar, se descarga y extrae la base de datos que contiene los artículos de noticias."
      ],
      "metadata": {
        "id": "deUmQaQSMOLm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, zipfile, io, os\n",
        "\n",
        "# Descargar el archivo\n",
        "url = \"https://zenodo.org/record/1239675/files/articles.zip?download=1\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Guardar en memoria y descomprimir\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    z.extractall()"
      ],
      "metadata": {
        "id": "jJFnDAFsnpWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construcción del DataFrame"
      ],
      "metadata": {
        "id": "p7i4p3b6nwyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez descargados, se leen los datos de los artículos (almacenados en formato XML) y se organizan en un DataFrame de pandas. La variable `data` resultante contiene: el **texto principal**, la **orientación política** y la **etiqueta de veracidad** de cada artículo."
      ],
      "metadata": {
        "id": "pa5Z7C0yPqxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Inicializar el diccionario de datos\n",
        "data = {\"mainText\": [], \"orientation\": [], \"veracity\": []}\n",
        "\n",
        "# Iterar sobre los archivos XML\n",
        "for filename in os.listdir(\"articles/\"):\n",
        "  # Parsear el archivo y obtener el elemento raíz\n",
        "  root = ET.parse(f\"articles/{filename}\").getroot()\n",
        "  # Iterar sobre los hijos directos de la raíz\n",
        "  for elem in root:\n",
        "      # Verificar si la etiqueta está entre las claves de interés\n",
        "      if elem.tag in data.keys():\n",
        "          # Agregar el texto a la lista correspondiente en el diccionario\n",
        "          data[elem.tag].append(elem.text)\n",
        "\n",
        "# Convertir a un DataFrame de pandas\n",
        "data = pd.DataFrame(data)\n",
        "# Eliminar filas que contengan valores nulos (NaN)\n",
        "data = data[data.notna().all(axis=\"columns\")]"
      ],
      "metadata": {
        "id": "8pofPMLHnzRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creación de los conjuntos de entrenamiento y testeo\n"
      ],
      "metadata": {
        "id": "wYWZjiCPqqH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de entrenar el modelo, se separa el conjunto original en **datos de entrenamiento** y **datos de testeo**. La partición típica de 80/20 permite que el modelo disponga de muestras variadas y reserve un subconjunto \"no visto\" a manera de control de calidad. Además, es conveniente **estratificar** la división según la etiqueta `veracity` para que se mantenga la proporción de clases en ambos subconjuntos, evitando sesgos; y se fija un `random_state`para garantizar reproducibilidad de los resultados en sucesivas ejecuciones."
      ],
      "metadata": {
        "id": "qb04BmvuLmw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# División de los datos en conjuntos de entrenamiento y testeo.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data[\"mainText\"],         # features: el texto principal de los artículos\n",
        "    data[\"veracity\"],         # target: la veracidad del artículo\n",
        "    test_size=0.2,            # Porcentaje de datos para el conjunto de testeo (20%)\n",
        "    random_state=42,          # Semilla que garantiza la misma división en cada ejecución\n",
        "    stratify=data[\"veracity\"] # Asegura que la distribución de las clases sea la misma en ambos conjuntos\n",
        ")"
      ],
      "metadata": {
        "id": "dbX8R6jHqtUx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento con CountVectorizer"
      ],
      "metadata": {
        "id": "AdUcavx5qxg3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez separadas las noticias, se convierten las palabras en vectores, para que el modelo pueda procesarlas.\n",
        "\n",
        "La vectorización de un documento consiste en definir una función $f(x_1,\\dots,x_n)$. El método más simple es la bolsa de palabras o Bag of Words (BoW) $f(x_1,\\dots,x_n)=x_1+\\dots+x_n$, donde cada coeficiente representa la **cantidad de veces que apareció** cada palabra del vocabulario.\n",
        "\n",
        "La clase `CountVectorizer` (sklearn), hace precisamente eso, convierte una colección de documentos de texto en una matriz de recuentos de tokens.\n",
        "\n",
        "Adicionalmente, permite aplicar normalizaciones básicas del procesamiento de lenguajes naturales (NLP):\n",
        "- `lowercase=True`: unifica mayúsculas y minúsculas\n",
        "- `stop_words='english'`: descarta palabras muy frecuentes o \"Stop Words\" (the, and, of, …) que no aportan a la clasificación.\n",
        "- `max_df=0.60`: elimina términos presentes en más del 60\\% de los artículos, porque su utilidad para clasificar es casi nula.\n",
        "- `min_df=3`: descarta palabras demasiado raras que aparecen en ménos de 3 documentos, que pueden ser ruido tipográfico."
      ],
      "metadata": {
        "id": "FvJGR0Baf_6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(\n",
        "    lowercase=True,       # pasar a minúscula\n",
        "    stop_words='english', # eliminar stopwords en inglés\n",
        "    max_df=0.6,           # eliminar términos que aparecen en más del 60% de los documentos\n",
        "    min_df=3              # eliminar términos que aparecen en menos de 3 documentos\n",
        ")\n",
        "\n",
        "# Entrenar el vectorizador\n",
        "X_train_vec = cv.fit_transform(X_train)\n",
        "\n",
        "# Transformar los datos de testeo\n",
        "X_test_vec = cv.transform(X_test)"
      ],
      "metadata": {
        "id": "kYQ-ZDHcqyWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (b) Entrenamiento de un modelo MNB"
      ],
      "metadata": {
        "id": "kErUJp6-nNXF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El algoritmo **Naive Bayes** es un enfoque de aprendizaje generativo utilizado para problemas de clasificación, que se basa en la modelización de la distribución condicional de las características dadas las clases, así como las probabilidades de clase a priori.\n",
        "\n",
        "Este algoritmo recibe su nombre de la \"hipótesis ingenua de Bayes\" que **asume que las características de entrada son condicionalmente independientes entre sí, dado el valor de la clase**. Por ejemplo en este caso, si se clasifica un artículo como `mostly true`, la ocurrencia de una palabra como `campaign` se considera independiente de la ocurrencia de otra palabra como `debate`, una vez que se sabe que el artículo es mayormente cierto. Aunque esta suposición es extremadamente fuerte y rara vez se cumple en la realidad, el algoritmo resultante a menudo funciona sorprendentemente bien en una variedad de problemas.\n",
        "\n",
        "En el contexto de la clasificación de texto, el algoritmo Naive Bayes puede emplear diferentes modelos de eventos. Sin embargo, para la mayoría de los problemas de clasificación de texto, el modelo de eventos multinomial (Multinomial Naive Bayes - MNB) es más adecuado y frecuentemente superior.\n",
        "\n",
        "En este caso, se busca predecir una clase $y\\in\\left\\{c_1,c_2,\\dots,c_K\\right\\}$ dado un documento $x$ representado como un vector de conteo de palabras:\n",
        "$$x=(x_1,x_2,\\dots,x_V)$$\n",
        "donde $x_i$ es la cantidad de veces que aparece la palabra $w_i$ y $V$ es el tamaño del vocabulario.\n",
        "\n",
        "En MNB el clasificador asigna la clase según:\n",
        "$$\\hat{y}=\\arg \\max_y p(y\\vert x)$$\n",
        "y, por el teorema de Bayes:\n",
        "$$p(y\\vert x)\\propto p(y)\\,p(x\\vert y)$$\n",
        "\n",
        "La hipótesis Naive asume que para cada posición $j$ del documento, se selecciona una palabra según una categórica:\n",
        "$$W_j\\vert Y=k\\sim \\text{Cat}\\left(p(w_1\\vert y),\\dots,p(w_V\\vert y)\\right)$$\n",
        "y cada palabra del documento es una observación independiente de la misma categórica de clase $k$.\n",
        "\n",
        "Luego, una vez generadas $N$ palabras de forma independiente de esa categórica, el número total de veces que aparece cada palabra sigue una multinomial:\n",
        "$$p(x\\vert y)=\\frac{N!}{x_1!x_2!\\dots x_V!}\\prod_{i=1}^Vp(w_i\\vert y)^{x_i}$$\n",
        "Donde $N=\\sum_{i=1}^Vx_i$ es la longitud total del documento.\n",
        "\n",
        "El coeficiente multinomial es independiente de $y$, entonces se puede omitir para la clasificación. Por lo tanto, para el clasificador:\n",
        "$$p(x\\vert y)\\propto \\prod_{i=1}^Vp(w_i\\vert y)^{x_i}$$\n",
        "\n",
        "Y tomando el logaritmo por cuestiones de estabilidad numérica:\n",
        "$$\\log p(x\\vert y)\\propto \\sum_{i=1}^V x_i \\log p(w_i\\vert y)$$\n",
        "\n",
        "La estimación de parámetros se hace por máxima verosimilitud.\n",
        "\n",
        "Para las probabilidades a priori:\n",
        "$$p(y=c_k)=\\frac{N_k}{N}$$\n",
        "donde $N_k$ es la cantidad de documentos de la clase $c_k$ y $N$ es la cantidad total de documentos.\n",
        "\n",
        "Para las condicionales:\n",
        "$$p(w_i\\vert y=c_k)=\\frac{N_{ik}}{N_k^\\text{total}}$$\n",
        "donde $N_{ik}$ es la cantidad total de veces que aparece la palabra $w_i$ en los documentos de la clase $c_k$ y $N_k^\\text{total}=\\sum_{j=1}^V N_{jk}$ es el total de palabras observadas en la clase $c_k$.\n",
        "\n",
        "Como puede haber palabras no vistas en alguna clase (lo que daría probabilidad cero), se aplica suavizado:\n",
        "\n",
        "$$p(w_i\\vert y=c_k)=\\frac{N_{ik}+\\alpha}{N_k^\\text{total}+\\alpha V}$$\n",
        "donde $\\alpha$ es el parámetro de suavizado.\n",
        "\n",
        "Por lo tanto, la expresión final para la clasificación es:\n",
        "$$\\log p(y=c_k\\vert x)\\propto \\log p(y=c_k)+\\sum_{i=1}^V x_i \\log p(w_i \\vert y=c_k)$$\n",
        "la cual se evalúa para cada clase $c_k$, y se elige aquella que tenga el máximo valor."
      ],
      "metadata": {
        "id": "_6TRL1dd37Yu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementación"
      ],
      "metadata": {
        "id": "FaNs5r6LrHKx"
      }
    },
    {
      "source": [
        "import numpy as np\n",
        "\n",
        "class MultinomialNB:\n",
        "    \"\"\"\n",
        "    Clase que implementa un clasificador Multinomial Naive Bayes.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha : float, default=1.0\n",
        "        Parámetro de suavizado. Evita probabilidades cero.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=1.0):\n",
        "        # Inicializa el parámetro de suavizado alfa\n",
        "        self.alpha = alpha\n",
        "        # Atributos que se inicializarán durante el entrenamiento (fit)\n",
        "        self.class_log_prior_ = None  # Logaritmo de la probabilidad a priori de cada clase\n",
        "        self.feature_log_prob_ = None # Logaritmo de la probabilidad de cada característica dado cada clase\n",
        "        self.classes_ = None          # Etiquetas de las clases únicas\n",
        "        self.n_classes_ = None        # Número de clases\n",
        "        self.n_features_ = None       # Número de características (tamaño del vocabulario)\n",
        "        self.feature_count_ = None    # Recuento de cada característica por clase (antes del suavizado)\n",
        "        self.class_count_ = None      # Recuento total de características por clase (antes del suavizado)\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Entrena el modelo Multinomial Naive Bayes.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : sparse matrix de forma (n_samples, n_features)\n",
        "            Vectores de features de entrenamiento.\n",
        "        y : array-like de forma (n_samples,)\n",
        "            Etiquetas de clase para las muestras de entrenamiento.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Retorna la instancia del modelo entrenado.\n",
        "        \"\"\"\n",
        "\n",
        "        # Encontrar las clases únicas y sus recuentos en las etiquetas de entrenamiento\n",
        "        self.classes_, counts = np.unique(y, return_counts=True)\n",
        "        # Determinar el número de clases y el número de características\n",
        "        self.n_classes_ = len(self.classes_)\n",
        "        self.n_features_ = X.shape[1]\n",
        "\n",
        "        # Calcular el logaritmo de la probabilidad a priori de cada clase\n",
        "        # P(C) = count(C) / total_samples\n",
        "        self.class_log_prior_ = np.log(counts / np.sum(counts))\n",
        "\n",
        "        # Inicializar matrices para almacenar el recuento de features por clase\n",
        "        # y el recuento total de features por clase\n",
        "        self.feature_count_ = np.zeros((self.n_classes_, self.n_features_))\n",
        "        self.class_count_ = np.zeros(self.n_classes_)\n",
        "\n",
        "        # Iterar a través de cada clase para calcular los recuentos de features\n",
        "        for idx, c in enumerate(self.classes_):\n",
        "            # Seleccionar las filas en X que corresponden a la clase 'c'\n",
        "            X_c = X[np.array(y) == c]\n",
        "            # Sumar los features (columnas) para obtener el recuento total de cada feature\n",
        "            # dentro de esta clase\n",
        "            self.feature_count_[idx, :] = X_c.sum(axis=0)\n",
        "            # Sumar todos los recuentos de features para obtener el recuento total de\n",
        "            # features (palabras) en todos los documentos de esta clase\n",
        "            self.class_count_[idx] = self.feature_count_[idx, :].sum()\n",
        "\n",
        "        # Calcular el logaritmo de la probabilidad de cada feature dado cada clase\n",
        "        # P(feature | class) = (count(feature, class) + alpha) / (sum(counts for class) + alpha * n_features)\n",
        "        # El suavizado de Laplace (sumar alpha) evita probabilidades cero\n",
        "        self.feature_log_prob_ = np.log(\n",
        "            (self.feature_count_ + self.alpha) / (self.class_count_[:, np.newaxis] + self.alpha * self.n_features_)\n",
        "        )\n",
        "\n",
        "        # Retornar la instancia del objeto entrenado\n",
        "        return self\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        \"\"\"\n",
        "        Calcula la probabilidad de cada clase para cada muestra en X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : sparse matrix de forma (n_samples, n_features)\n",
        "            Vectores de features de entrada.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        probs : array-like de forma (n_samples, n_classes)\n",
        "            Probabilidad de cada clase para cada muestra en X.\n",
        "        \"\"\"\n",
        "\n",
        "        # Calcular el logaritmo de la probabilidad no normalizada para cada clase y muestra\n",
        "        # log(P(C | D)) = log(P(C)) + sum(log(P(feature | C)) por cada feature en D)\n",
        "        # Donde P(C | D) es la probabilidad posterior de la clase dado el documento\n",
        "        log_probs = self.class_log_prior_ + X @ self.feature_log_prob_.T\n",
        "\n",
        "        # Normalizar los logaritmos de probabilidades para la estabilidad numérica\n",
        "        # Esto evita que la exponenciación de números muy pequeños resulte en cero\n",
        "        log_probs_norm = log_probs - log_probs.max(axis=1, keepdims=True)\n",
        "\n",
        "        # Convertir los logaritmos de probabilidades normalizados a probabilidades\n",
        "        probs = np.exp(log_probs_norm)\n",
        "\n",
        "        # Normalizar las probabilidades para que sumen 1 para cada muestra\n",
        "        probs = probs / probs.sum(axis=1, keepdims=True)\n",
        "\n",
        "        return probs\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predice la etiqueta de clase para cada muestra en X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : sparse matrix de forma (n_samples, n_features)\n",
        "            Vectores de features de entrada.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        y_pred : array-like de forma (n_samples,)\n",
        "            Etiquetas de clase predichas para cada muestra en X.\n",
        "        \"\"\"\n",
        "        # Obtener las probabilidades de cada clase para cada muestra\n",
        "        probs = self.predict_proba(X)\n",
        "        # Encontrar el índice de la clase con la probabilidad máxima para cada muestra\n",
        "        class_idx = np.argmax(probs, axis=1)\n",
        "        # Retornar las etiquetas de clase correspondientes a los índices encontrados\n",
        "        return self.classes_[class_idx]"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "WO4Ww9U8v7vv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (c) Inferencia"
      ],
      "metadata": {
        "id": "fvW1HcqPnPmQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una creado el modelo MNB, se implementan dos métricas de evaluación utilizadas en trabajos prácticos anteriores para observar su desempeño:\n",
        "- **Accuracy**: mide la proporción de artículos correctamente clasificados sobre el total.\n",
        "- **Macro-F1**: promedia el F1-score calculado por clase, asignando igual peso a cada clase, independientemente de su cantidad de muestras.\n",
        "\n",
        "| **Métrica**                    | **Expresión Matemática para su evaluación**                                                                | **Descripción**                                                                          |\n",
        "| ------------------------------ | ---------------------------------------------------------------------------------------------------------------| ---------------------------------------------------------------------------------------- |\n",
        "| **Accuracy**                   | $\\text{Accuracy} = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbb{1}(y_i = \\hat{y}_i)$ | Proporción total de muestras correctamente clasificadas.                                 |\n",
        "| **Precisión (para clase $c$)** | $P_c = \\frac{\\mathrm{TP}_c}{\\mathrm{TP}_c + \\mathrm{FP}_c}$                | Porcentaje de predicciones correctas entre las predicciones positivas para la clase $c$. |\n",
        "| **Recall (para clase $c$)**    | $R_c = \\frac{\\mathrm{TP}_c}{\\mathrm{TP}_c + \\mathrm{FN}_c}$                | Porcentaje de verdaderos positivos entre todos los casos reales de la clase $c$.         |\n",
        "| **F1-score (para clase $c$)**  | $F1_c = \\frac{2 \\cdot P_c \\cdot R_c}{P_c + R_c}$                           | Media armónica entre precisión y recall para la clase $c$.                               |\n",
        "| **Macro-F1**                   | $\\text{Macro-F1} = \\frac{1}{K} \\sum_{c=1}^{K} F1_c$                        | Promedio del F1-score calculado sobre todas las clases.                                  |\n"
      ],
      "metadata": {
        "id": "BpBAiZWmIJ9x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implementación de las métricas"
      ],
      "metadata": {
        "id": "QH7IANvHrpU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(self, X, y_true):\n",
        "    \"\"\"\n",
        "    Calcula accuracy y Macro-F1 sobre el conjunto X, y_true.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : sparse matrix de forma (n_samples, n_features)\n",
        "        Vectores de features para la evaluación.\n",
        "    y_true : array-like de forma (n_samples,)\n",
        "        Etiquetas de clase verdaderas.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    accuracy : float\n",
        "        Precisión (accuracy) del modelo.\n",
        "    macro_f1 : float\n",
        "        Macro-F1 del modelo.\n",
        "    \"\"\"\n",
        "\n",
        "    # Realizar predicciones sobre los datos de evaluación\n",
        "    y_pred = self.predict(X)\n",
        "\n",
        "    # Calcular la precisión (accuracy)\n",
        "    accuracy = np.mean(y_pred == y_true)\n",
        "\n",
        "    # Inicializar una lista para almacenar los scores F1 por clase\n",
        "    f1_scores = []\n",
        "    # Iterar a través de cada clase única\n",
        "    for c in self.classes_:\n",
        "        # Calcular los verdaderos positivos (TP), falsos positivos (FP) y falsos negativos (FN)\n",
        "        TP = np.sum((y_pred == c) & (y_true == c))\n",
        "        FP = np.sum((y_pred == c) & (y_true != c))\n",
        "        FN = np.sum((y_pred != c) & (y_true == c))\n",
        "\n",
        "        # Calcular la precisión para la clase actual\n",
        "        # Maneja la división por cero si TP + FP es cero\n",
        "        precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "        # Calcular el recall para la clase actual\n",
        "        # Maneja la división por cero si TP + FN es cero\n",
        "        recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "\n",
        "        # Calcular el score F1 para la clase actual\n",
        "        # Maneja la división por cero si precision + recall es cero\n",
        "        if precision + recall > 0:\n",
        "            f1 = 2 * precision * recall / (precision + recall)\n",
        "        else:\n",
        "            f1 = 0\n",
        "\n",
        "        # Agregar el score F1 de la clase actual a la lista\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    # Calcular el Macro-F1 como el promedio de los scores F1 de cada clase\n",
        "    macro_f1 = np.mean(f1_scores)\n",
        "\n",
        "    return accuracy, macro_f1\n",
        "\n",
        "# Agregar el método 'evaluate' a la clase MultinomialNB\n",
        "MultinomialNB.evaluate = evaluate"
      ],
      "metadata": {
        "id": "3ndp-hmYrn28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación de las métricas en el conjunto de testeo"
      ],
      "metadata": {
        "id": "oqGF1D3FrsTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al evaluar las métricas de Accuracy y Macro-F1 sobre el conjunto de testeo se observa que **sus valores son muy diferentes**:\n",
        "- Accuracy= 0.7227\n",
        "- Macro-F1= 0.4417.\n",
        "\n",
        "Este resultado es esperable en datasets desbalanceados como el *BuzzFeed-Webis*.\n",
        "\n",
        "Como se puede ver en el cuadro de  conteo de cada categoría de veracidad, `mostly true` y `mixture of true and false` tienen más ejemplos, mientras que el resto tiene menos.\n",
        "\n",
        "Entonces, si el modelo logra clasificar bien las clases mayoritarias, obtiene un **Accuracy** alto, incluso sin acertar mucho las clases minoritarias. Es decir, le **da el mismo peso a cada muestra, sin importar la clase**.\n",
        "\n",
        "La **Macro-F1** en cambio, **le da el mismo peso a cada clase, no a cada muestra**. Por lo tanto, si hay clases que tienen pocos ejemplos y el modelo las predice mal, su valor disminuye.\n",
        "\n",
        "Ese es el motivo por el que en problemas de clasificación desbalanceada se reporta Macro-F1 y no sólo Accuracy.\n",
        "\n",
        "Por último, en este problema donde se evalúa la veracidad, hay **pocas palabras fuertemente indicativas de la clase**, es decir, pueden existir muchas palabras compartidas entre noticias verdaderas y falsas."
      ],
      "metadata": {
        "id": "BYE6cDodQujz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear una instancia de la clase MultinomialNB\n",
        "mnb_veracity = MultinomialNB(alpha=1.0)\n",
        "# Entrenar el modelo\n",
        "mnb_veracity.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluar el rendimiento del modelo entrenado en el conjunto de testeo\n",
        "accuracy, macro_f1 = mnb_veracity.evaluate(X_test_vec, y_test)\n",
        "\n",
        "# Imprimir las métricas de evaluación\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Macro-F1: {macro_f1:.4f}\")\n",
        "\n",
        "# Mostrar el conteo de cada categoría de veracidad en el DataFrame original\n",
        "data['veracity'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "khK7J7MGrtpI",
        "outputId": "fde6dbcf-6961-482a-e7bd-325c2e2686c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7227\n",
            "Macro-F1: 0.4417\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "veracity\n",
              "mostly true                  1249\n",
              "mixture of true and false     209\n",
              "mostly false                   82\n",
              "no factual content             64\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>veracity</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mostly true</th>\n",
              "      <td>1249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mixture of true and false</th>\n",
              "      <td>209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mostly false</th>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no factual content</th>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (d) Orientación"
      ],
      "metadata": {
        "id": "I48E4IyenRvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez finalizado el análisis de la veracidad, se repite el procedimiento anterior, pero con el objetivo de predecir la orientación política del portal donde fue publicada la noticia: `left`, `right` o `mainstream`.\n",
        "\n",
        "Al igual que en el punto anterior, se evalúan las métricas Accuracy y Macro-F1 para analizar el desempeño global. Los resultados son:\n",
        "- Accuracy: 0.8037\n",
        "- Macro-F1: 0.7691\n",
        "\n",
        "Estos resultados son más consistentes que los obtenidos en el punto (c), donde había una gran diferencia entre ambas métricas.\n",
        "\n",
        "Una de las principales razones de la mejora es que, en el caso de la orientación política, este dataset está **menos desbalanceado**. Esto se puede observar del cuadro de conteo de cada categoría de orientación.\n",
        "\n",
        "Adicionalmente, en este caso, el texto contiene **patrones lingüísticos más indicativos** de la orientación política. Hay palabras o expresiones que son más frecuentes en portales de izquierda, derecha o mainstream.\n",
        "\n",
        "En otras palabras, clasificar la veracidad es un problema mucho más difícil, debido al dataset desbalanceado y los patrones lingüísticos más sutiles, mientras que, para la orientación, el dataset está mejor balanceado y los patrones lingüísticos son más claros."
      ],
      "metadata": {
        "id": "iYqaLzx2Z6eZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar las características de entrada (texto principal) y la variable objetivo (orientación política)\n",
        "X_text = data[\"mainText\"]\n",
        "y_orientation = data[\"orientation\"]\n",
        "\n",
        "# Dividir el conjunto de datos en conjuntos de entrenamiento y prueba.\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_text,                 # features: el texto principal de los artículos\n",
        "    y_orientation,          # target: la orientación del portal\n",
        "    test_size=0.2,          # Asigna el 20% de los datos al conjunto de prueba.\n",
        "    random_state=42,        # Asegura que la división sea la misma cada vez para reproducibilidad.\n",
        "    stratify=y_orientation  # Mantiene la misma proporción de clases de orientación en ambos conjuntos.\n",
        ")\n",
        "\n",
        "# Crear una instancia de CountVectorizer para convertir el texto en vectores de conteo de palabras\n",
        "cv = CountVectorizer(\n",
        "    lowercase=True,        # Convierte todo a minúsculas\n",
        "    stop_words='english',  # Elimina palabras comunes en inglés\n",
        "    max_df=0.6,            # Elimina términos que aparecen en más del 60% de los documentos\n",
        "    min_df=3               # Elimina términos que aparecen en menos de 3 documentos\n",
        ")\n",
        "\n",
        "# Entrenar el vectorizador con los datos de entrenamiento y transformarlos\n",
        "X_train_vec = cv.fit_transform(X_train)\n",
        "# Transformar los datos de prueba usando el mismo vocabulario aprendido\n",
        "X_test_vec = cv.transform(X_test)\n",
        "\n",
        "# Crear una instancia del clasificador Multinomial Naive Bayes.\n",
        "mnb_orientation = MultinomialNB(alpha=1.0)\n",
        "# Entrenar el modelo MNB con los datos de entrenamiento vectorizados y sus etiquetas de orientación\n",
        "mnb_orientation.fit(X_train_vec, y_train)\n",
        "\n",
        "# Evaluar el modelo entrenado en el conjunto de prueba\n",
        "accuracy, macro_f1 = mnb_orientation.evaluate(X_test_vec, y_test)\n",
        "\n",
        "# Imprimir los valores de las métricas de evaluación\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Macro-F1: {macro_f1:.4f}\")\n",
        "\n",
        "# Mostrar el conteo de cada categoría de orientación política en el DataFrame original\n",
        "data['orientation'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "Rrp9A_GgsEKy",
        "outputId": "8bbf81cc-9cce-422d-cff4-83e9caddd162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8037\n",
            "Macro-F1: 0.7691\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "orientation\n",
              "mainstream    822\n",
              "right         530\n",
              "left          252\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>orientation</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>mainstream</th>\n",
              "      <td>822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>right</th>\n",
              "      <td>530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>left</th>\n",
              "      <td>252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}